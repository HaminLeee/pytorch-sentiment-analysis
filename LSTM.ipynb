{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBVJZj7AC-22"
      },
      "source": [
        "# LSTM for Sentiment Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE4XwwvmC-2_"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFuQVmheIz0O",
        "outputId": "9d3c315c-7be3-46b5-911b-d3c5db57ba21"
      },
      "source": [
        "pip install torch==1.8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.8 in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbThLFRWHuyJ",
        "outputId": "fe347721-1806-4374-91ad-2586ddcd65b2"
      },
      "source": [
        "pip install torchtext==0.9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext==0.9 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (2.23.0)\n",
            "Requirement already satisfied: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (1.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9) (1.19.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchtext==0.9) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x759LJ47C-3B"
      },
      "source": [
        "Load the Twitter dataset from drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SruUcFQSCvap",
        "outputId": "e57cc39c-4a5b-4047-9f52-f3c04973521d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-PbkWBsC-yE"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/gdrive/My Drive/kaggle/input/twitter-and-reddit-sentimental-analysis-dataset/Twitter_Data.csv', dtype=str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pgkftGMmn1r"
      },
      "source": [
        "Clean up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1R1VG9KC-3B"
      },
      "source": [
        "df.columns = ['text', 'label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-zM2YJmDCCa"
      },
      "source": [
        "df.dropna(inplace=True)\n",
        "df['label'] = df['label'].astype(str).astype(int)\n",
        "df['text'] = df['text'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UibJAyu8DHWA"
      },
      "source": [
        "cat = list(df['label'])\n",
        "neutral = [i for i, e in enumerate(cat) if e == 0]\n",
        "df = df.drop(df.index[neutral])\n",
        "df['label'] = df['label'].replace([-1], 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_0-3q8rDKAX"
      },
      "source": [
        "df = df[:5000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "tt7QN6EtgCO2",
        "outputId": "7bbc00c0-409b-4c2e-c290-d42efc3d8e2d"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>with upcoming election india saga going import...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7674</th>\n",
              "      <td>modi wants cabinet with remote controll</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7675</th>\n",
              "      <td>you think few thousand rupees most likely the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7680</th>\n",
              "      <td>first understand what told nowhere campaigned ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7681</th>\n",
              "      <td>the saddest thing that rahul may never his lif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7682</th>\n",
              "      <td>basis this modi 2014 had said all these monies...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  label\n",
              "0     when modi promised “minimum government maximum...      0\n",
              "2     what did just say vote for modi  welcome bjp t...      1\n",
              "3     asking his supporters prefix chowkidar their n...      1\n",
              "4     answer who among these the most powerful world...      1\n",
              "8     with upcoming election india saga going import...      1\n",
              "...                                                 ...    ...\n",
              "7674            modi wants cabinet with remote controll      1\n",
              "7675  you think few thousand rupees most likely the ...      1\n",
              "7680  first understand what told nowhere campaigned ...      1\n",
              "7681  the saddest thing that rahul may never his lif...      1\n",
              "7682  basis this modi 2014 had said all these monies...      0\n",
              "\n",
              "[5000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vIH84aROLHD"
      },
      "source": [
        "from torchtext.legacy.data import Dataset, Example\n",
        "\n",
        "ltoi = {l: i for i, l in enumerate(df['label'].unique())}\n",
        "df['label'] = df['label'].apply(lambda y: ltoi[y])\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJXZSVd2nrTF"
      },
      "source": [
        "Set the seed, define the Fields and get the training/valid/test splits.\n",
        "\n",
        "We'll be using packed padded sequences, which will make our RNN only process the non-padded elements of our sequence, and for any padded element the output will be a zero tensor. To use packed padded sequences, we have to tell the RNN how long the actual sequences are. We do this by setting include_lengths = True for our TEXT field. This will cause batch.text to now be a tuple with the first element being our sentence (a numericalized tensor that has been padded) and the second element being the actual lengths of our sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55Dmhg7TC-3A"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext.legacy.data import Field, LabelField, BucketIterator\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = Field(tokenize = 'spacy',\n",
        "              tokenizer_language = 'en_core_web_sm',\n",
        "              include_lengths = True)\n",
        "\n",
        "LABEL = LabelField(dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mgjb4OwQaWD"
      },
      "source": [
        "train_data, test_data = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', TEXT),\n",
        "        ('label', LABEL)\n",
        "    )\n",
        ").split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqBOgbzSQ7yw"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osOvBQEkC-3D"
      },
      "source": [
        "Instead of having our word embeddings initialized randomly, they are initialized with these pre-trained vectors.\n",
        "We get these vectors simply by specifying which vectors we want and passing it as an argument to `build_vocab`. `TorchText` handles downloading the vectors and associating them with the correct words in our vocabulary.\n",
        "\n",
        "We will be using the `\"glove.6B.100d\" vectors\"`. `glove` is the algorithm used to calculate the vectors, go [here](https://nlp.stanford.edu/projects/glove/) for more. `6B` indicates these vectors were trained on 6 billion tokens and `100d` indicates these vectors are 100-dimensional.\n",
        "\n",
        "\n",
        "The theory is that these pre-trained vectors already have words with similar semantic meaning close together in vector space, e.g. \"terrible\", \"awful\", \"dreadful\" are nearby. This gives our embedding layer a good initialization as it does not have to learn these relations from scratch.\n",
        "\n",
        "**Note**: these vectors are about 862MB, so watch out if you have a limited internet connection.\n",
        "\n",
        "By default, TorchText will initialize words in your vocabulary but not in your pre-trained embeddings to zero. We don't want this, and instead initialize them randomly by setting `unk_init` to `torch.Tensor.normal_`. This will now initialize those words via a Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTxD2Me4C-3D"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25000\n",
        "\n",
        "TEXT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOXAJ1qcC-3E"
      },
      "source": [
        "Next, create the iterators, placing the tensors on the GPU if one is available.\n",
        "\n",
        "**Note**: For packed padded sequences all of the tensors within a batch need to be sorted by their lengths. This is handled in the iterator by setting `sort_within_batch = True`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rzjMJR_C-3E"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    sort_key=lambda x: len(x.text),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_within_batch = True,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yrn8P0WC-3E"
      },
      "source": [
        "## Build the Model\n",
        "\n",
        "The model features the most drastic changes.\n",
        "\n",
        "### Different RNN Architecture\n",
        "\n",
        "We'll be using a different RNN architecture called a Long Short-Term Memory (LSTM). Why is an LSTM better than a standard RNN? Standard RNNs suffer from the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). LSTMs overcome this by having an extra recurrent state called a _cell_, $c$ - which can be thought of as the \"memory\" of the LSTM - and the use use multiple _gates_ which control the flow of information into and out of the memory. For more information, go [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). We can simply think of the LSTM as a function of $x_t$, $h_t$ and $c_t$, instead of just $x_t$ and $h_t$.\n",
        "\n",
        "$$(h_t, c_t) = \\text{LSTM}(x_t, h_t, c_t)$$\n",
        "\n",
        "Thus, the model using an LSTM looks something like (with the embedding layers omitted):\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment2.png?raw=1)\n",
        "\n",
        "The initial cell state, $c_0$, like the initial hidden state is initialized to a tensor of all zeros. The sentiment prediction is still, however, only made using the final hidden state, not the final cell state, i.e. $\\hat{y}=f(h_T)$.\n",
        "\n",
        "### Bidirectional RNN\n",
        "\n",
        "The concept behind a bidirectional RNN is simple. As well as having an RNN processing the words in the sentence from the first to the last (a forward RNN), we have a second RNN processing the words in the sentence from the **last to the first** (a backward RNN). At time step $t$, the forward RNN is processing word $x_t$, and the backward RNN is processing word $x_{T-t+1}$. \n",
        "\n",
        "In PyTorch, the hidden state (and cell state) tensors returned by the forward and backward RNNs are stacked on top of each other in a single tensor. \n",
        "\n",
        "We make our sentiment prediction using a concatenation of the last hidden state from the forward RNN (obtained from final word of the sentence), $h_T^\\rightarrow$, and the last hidden state from the backward RNN (obtained from the first word of the sentence), $h_T^\\leftarrow$, i.e. $\\hat{y}=f(h_T^\\rightarrow, h_T^\\leftarrow)$   \n",
        "\n",
        "The image below shows a bi-directional RNN, with the forward RNN in orange, the backward RNN in green and the linear layer in silver.  \n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment3.png?raw=1)\n",
        "\n",
        "### Multi-layer RNN\n",
        "\n",
        "Multi-layer RNNs (also called *deep RNNs*) are another simple concept. The idea is that we add additional RNNs on top of the initial standard RNN, where each RNN added is another *layer*. The hidden state output by the first (bottom) RNN at time-step $t$ will be the input to the RNN above it at time step $t$. The prediction is then made from the final hidden state of the final (highest) layer.\n",
        "\n",
        "The image below shows a multi-layer unidirectional RNN, where the layer number is given as a superscript. Also note that each layer needs their own initial hidden state, $h_0^L$.\n",
        "\n",
        "![](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/assets/sentiment4.png?raw=1)\n",
        "\n",
        "### Regularization\n",
        "\n",
        "Although we've added improvements to our model, each one adds additional parameters. Without going into overfitting into too much detail, the more parameters you have in in your model, the higher the probability that your model will overfit (memorize the training data, causing  a low training error but high validation/testing error, i.e. poor generalization to new, unseen examples). To combat this, we use regularization. More specifically, we use a method of regularization called *dropout*. Dropout works by randomly *dropping out* (setting to 0) neurons in a layer during a forward pass. The probability that each neuron is dropped out is set by a hyperparameter and each neuron with dropout applied is considered indepenently. One theory about why dropout works is that a model with parameters dropped out can be seen as a \"weaker\" (less parameters) model. The predictions from all these \"weaker\" models (one for each forward pass) get averaged together withinin the parameters of the model. Thus, your one model can be thought of as an ensemble of weaker models, none of which are over-parameterized and thus should not overfit.\n",
        "\n",
        "### Implementation Details\n",
        "\n",
        "Another addition to this model is that we are not going to learn the embedding for the `<pad>` token. This is because we want to explitictly tell our model that padding tokens are irrelevant to determining the sentiment of a sentence. This means the embedding for the pad token will remain at what it is initialized to (we initialize it to all zeros later). We do this by passing the index of our pad token as the `padding_idx` argument to the `nn.Embedding` layer.\n",
        "\n",
        "To use an LSTM instead of the standard RNN, we use `nn.LSTM` instead of `nn.RNN`. Also, note that the LSTM returns the `output` and a tuple of the final `hidden` state and the final `cell` state, whereas the standard RNN only returned the `output` and final `hidden` state. \n",
        "\n",
        "As the final hidden state of our LSTM has both a forward and a backward component, which will be concatenated together, the size of the input to the `nn.Linear` layer is twice that of the hidden dimension size.\n",
        "\n",
        "Implementing bidirectionality and adding additional layers are done by passing values for the `num_layers` and `bidirectional` arguments for the RNN/LSTM. \n",
        "\n",
        "Dropout is implemented by initializing an `nn.Dropout` layer (the argument is the probability of dropping out each neuron) and using it within the `forward` method after each layer we want to apply dropout to. **Note**: never use dropout on the input or output layers (`text` or `fc` in this case), you only ever want to use dropout on intermediate layers. The LSTM has a `dropout` argument which adds dropout on the connections between hidden states in one layer to hidden states in the next layer. \n",
        "\n",
        "As we are passing the lengths of our sentences to be able to use packed padded sequences, we have to add a second argument, `text_lengths`, to `forward`. \n",
        "\n",
        "Before we pass our embeddings to the RNN, we need to pack them, which we do with `nn.utils.rnn.packed_padded_sequence`. This will cause our RNN to only process the non-padded elements of our sequence. The RNN will then return `packed_output` (a packed sequence) as well as the `hidden` and `cell` states (both of which are tensors). Without packed padded sequences, `hidden` and `cell` are tensors from the last element in the sequence, which will most probably be a pad token, however when using packed padded sequences they are both from the last non-padded element in the sequence. Note that the `lengths` argument of `packed_padded_sequence` must be a CPU tensor so we explicitly make it one by using `.to('cpu')`.\n",
        "\n",
        "We then unpack the output sequence, with `nn.utils.rnn.pad_packed_sequence`, to transform it from a packed sequence to a tensor. The elements of `output` from padding tokens will be zero tensors (tensors where every element is zero). Usually, we only have to unpack output if we are going to use it later on in the model. Although we aren't in this case, we still unpack the sequence just to show how it is done.\n",
        "\n",
        "The final hidden state, `hidden`, has a shape of _**[num layers * num directions, batch size, hid dim]**_. These are ordered: **[forward_layer_0, backward_layer_0, forward_layer_1, backward_layer 1, ..., forward_layer_n, backward_layer n]**. As we want the final (top) layer forward and backward hidden states, we get the top two hidden layers from the first dimension, `hidden[-2,:,:]` and `hidden[-1,:,:]`, and concatenate them together before passing them to the linear layer (after applying dropout). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxZ1jQQ7C-3I"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'))\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "                \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-fbudsfC-3J"
      },
      "source": [
        "Create an instance of our RNN class, with the new parameters and arguments for the number of layers, bidirectionality and dropout probability.\n",
        "\n",
        "To ensure the pre-trained vectors can be loaded into the model, the `EMBEDDING_DIM` must be equal to that of the pre-trained GloVe vectors loaded earlier.\n",
        "\n",
        "We get our pad token index from the vocabulary, getting the actual string representing the pad token from the field's `pad_token` attribute, which is `<pad>` by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLRZ0rvrC-3J"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jhocop4C-3J"
      },
      "source": [
        "Print out the number of parameters in our model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFmDW5Y_C-3K",
        "outputId": "4664c884-3dd8-483b-f461-581f7aeccb74"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 3,265,957 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efAMBkJ6C-3K"
      },
      "source": [
        "The final addition is copying the pre-trained word embeddings we loaded earlier into the `embedding` layer of our model.\n",
        "\n",
        "We retrieve the embeddings from the field's vocab, and check they're the correct size, _**[vocab size, embedding dim]**_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2KuZ5WpC-3L",
        "outputId": "42d77ccd-ac28-462c-ffca-180cf52d56ec"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([9553, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpzErsiUC-3L"
      },
      "source": [
        "We then replace the initial weights of the `embedding` layer with the pre-trained embeddings.\n",
        "\n",
        "**Note**: this should always be done on the `weight.data` and not the `weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD0UbRn_C-3L",
        "outputId": "49dccdfb-8b51-494b-9269-c477eac7b583"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [-0.3373, -0.5434, -0.0871,  ...,  0.6306, -0.1431,  0.2725],\n",
              "        ...,\n",
              "        [ 1.1487, -1.6731,  2.5546,  ..., -0.8669, -1.6263,  1.4020],\n",
              "        [-0.7552, -0.2910, -3.5319,  ...,  0.8365, -0.1758,  0.6478],\n",
              "        [ 0.7507,  0.3689, -1.1197,  ...,  0.6473,  0.4238,  0.0511]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw2bCH2xC-3M"
      },
      "source": [
        "As our `<unk>` and `<pad>` token aren't in the pre-trained vocabulary they have been initialized using `unk_init` (an $\\mathcal{N}(0,1)$ distribution) when building our vocab. It is preferable to initialize them both to all zeros to explicitly tell our model that, initially, they are irrelevant for determining sentiment. \n",
        "\n",
        "We do this by manually setting their row in the embedding weights matrix to zeros. We get their row by finding the index of the tokens, which we have already done for the padding index.\n",
        "\n",
        "**Note**: like initializing the embeddings, this should be done on the `weight.data` and not the `weight`!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAENGNfWC-3M",
        "outputId": "b1a7c300-6024-45ec-f734-3db8abaac350"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "\n",
        "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.3373, -0.5434, -0.0871,  ...,  0.6306, -0.1431,  0.2725],\n",
            "        ...,\n",
            "        [ 1.1487, -1.6731,  2.5546,  ..., -0.8669, -1.6263,  1.4020],\n",
            "        [-0.7552, -0.2910, -3.5319,  ...,  0.8365, -0.1758,  0.6478],\n",
            "        [ 0.7507,  0.3689, -1.1197,  ...,  0.6473,  0.4238,  0.0511]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3H7wo_KC-3M"
      },
      "source": [
        "We can now see the first two rows of the embedding weights matrix have been set to zeros. As we passed the index of the pad token to the `padding_idx` of the embedding layer it will remain zeros throughout training, however the `<unk>` token embedding will be learned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br1jiZ1oC-3M"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkXtI-wzC-3M"
      },
      "source": [
        "Now to training the model.\n",
        "\n",
        "We use the `Adam` optimizer for the LSTM model. `Adam` adapts the learning rate for each parameter, giving parameters that are updated more frequently lower learning rates and parameters that are updated infrequently higher learning rates. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29OgrzhdC-3N"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3fNjoXNC-3N"
      },
      "source": [
        "Define the criterion and place the model and criterion on the GPU (if available)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uu3_t024C-3N"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCZiNN3XC-3N"
      },
      "source": [
        "and implement the function to calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-ojiX1FC-3N"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIk4ozTwC-3N"
      },
      "source": [
        "Define a function for training the LSTM model. \n",
        "\n",
        "As we have set `include_lengths = True`, our `batch.text` is now a tuple with the first element being the numericalized tensor and the second element being the actual lengths of each sequence. We separate these into their own variables, `text` and `text_lengths`, before passing them to the model.\n",
        "\n",
        "**Note**: as we are now using dropout, we must remember to use `model.train()` to ensure the dropout is \"turned on\" while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z4sDyglC-3N"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naRgg_FzC-3O"
      },
      "source": [
        "Then define a function for testing our model.\n",
        "\n",
        "**Note**: as we are now using dropout, we must remember to use `model.eval()` to ensure the dropout is \"turned off\" while evaluating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVQpQUzOC-3O"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvDx_dXGC-3O"
      },
      "source": [
        "and also create a function that tells us how long each epoch is taking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmuqjkFhC-3O"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9sxNwRlC-3O"
      },
      "source": [
        "Finally, we train the model over 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AzVALM4C-3P",
        "outputId": "e14ad6cf-63a4-4208-8146-284731b17bb1"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "all_train_acc, all_train_loss = [], []\n",
        "all_valid_acc, all_valid_loss = [], []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    all_train_acc.append(train_acc)\n",
        "    all_train_loss.append(train_loss)\n",
        "    all_valid_acc.append(valid_acc)\n",
        "    all_valid_loss.append(valid_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'lstm.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.654 | Train Acc: 63.83%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 64.93%\n",
            "Epoch: 02 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.602 | Train Acc: 67.99%\n",
            "\t Val. Loss: 0.584 |  Val. Acc: 69.93%\n",
            "Epoch: 03 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.547 | Train Acc: 73.84%\n",
            "\t Val. Loss: 0.564 |  Val. Acc: 70.94%\n",
            "Epoch: 04 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.490 | Train Acc: 76.13%\n",
            "\t Val. Loss: 0.565 |  Val. Acc: 70.93%\n",
            "Epoch: 05 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.457 | Train Acc: 77.96%\n",
            "\t Val. Loss: 0.536 |  Val. Acc: 74.75%\n",
            "Epoch: 06 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.396 | Train Acc: 82.68%\n",
            "\t Val. Loss: 0.501 |  Val. Acc: 77.83%\n",
            "Epoch: 07 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.335 | Train Acc: 85.13%\n",
            "\t Val. Loss: 0.510 |  Val. Acc: 76.90%\n",
            "Epoch: 08 | Epoch Time: 0m 31s\n",
            "\tTrain Loss: 0.330 | Train Acc: 85.71%\n",
            "\t Val. Loss: 0.583 |  Val. Acc: 73.71%\n",
            "Epoch: 09 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.284 | Train Acc: 88.16%\n",
            "\t Val. Loss: 0.514 |  Val. Acc: 77.09%\n",
            "Epoch: 10 | Epoch Time: 0m 32s\n",
            "\tTrain Loss: 0.230 | Train Acc: 90.64%\n",
            "\t Val. Loss: 0.515 |  Val. Acc: 77.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCwseS0up9FJ"
      },
      "source": [
        "Plot the graph for the loss and accuracy of the model over each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "ZQArVIAhjUr5",
        "outputId": "c23832b2-08fd-433a-d356-d3382991b4c4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(list(range(N_EPOCHS)), all_train_acc, label=\"training accuracy\")\n",
        "plt.plot(list(range(N_EPOCHS)), all_valid_acc, label=\"validation accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"LSTM accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(list(range(N_EPOCHS)), all_train_loss, label=\"training loss\")\n",
        "plt.plot(list(range(N_EPOCHS)), all_valid_loss, label=\"validation loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"LSTM loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0HJjnP3qMIV"
      },
      "source": [
        "Then test the trained model on our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB6XXVlTC-3P",
        "outputId": "bb75dedd-6d65-4648-dca9-2e34c349cd88"
      },
      "source": [
        "model.load_state_dict(torch.load('lstm.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.504 | Test Acc: 75.20%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}